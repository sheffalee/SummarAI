{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1aead955-0231-4ead-a730-8fb95447fe81",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "1aead955-0231-4ead-a730-8fb95447fe81"
      },
      "source": [
        "<b>Team Name</b> : MeowCoders<br>\n",
        "<b>Hack Name</b> : SummarAI<br>\n",
        "<b>Theme</b>     : 3<br>\n",
        "<b>Members</b>   : <br>\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Name</th>\n",
        "    <th>Email</th>\n",
        "    <th>Branch & Year</th>\n",
        "    <th>Phone</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Sam Prince Franklin K</td>\n",
        "    <td>samprince.franklink2020@vitstudent.ac.in</td>\n",
        "    <td>M.Tech Integrated Software Engineering & 4th Year</td>\n",
        "    <td>7010267239</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>Sheffalee T S</td>\n",
        "    <td>sheffalee.ts2020@vitstudent.ac.in</td>\n",
        "    <td>M.Tech Integrated Software Engineering & 4th Year</td>\n",
        "    <td>9384185843</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>Shakthi B</td>\n",
        "    <td>shakthi.b2020@vitstudent.ac.in</td>\n",
        "    <td>M.Tech Integrated Software Engineering & 4th Year</td>\n",
        "    <td>8248518962</td>\n",
        "  </tr>\n",
        "   \n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e6b0c8b-bd10-4bcd-9019-64fd48408bdb",
      "metadata": {
        "id": "4e6b0c8b-bd10-4bcd-9019-64fd48408bdb"
      },
      "source": [
        "## Background\n",
        "\n",
        "In the bustling virtual corridors of **Tiruvannamalai Elementary School**, educators, parents, and students gather in the digital realm. Online meetings have become the norm—a canvas where learning, collaboration, and decision-making unfold. But within this digital landscape lies a challenge: the deluge of spoken content during these meetings.\n",
        "\n",
        "## Problems Identified\n",
        "\n",
        "1. **Information Overload**:\n",
        "   - **Issue**: Teachers conduct daily virtual classes, PTA meetings, and faculty discussions. Students attend online lectures, group projects, and extracurricular club sessions. The sheer volume of spoken content—transcripts, notes, and action items—becomes overwhelming.\n",
        "   - **Impact**: Educators struggle to sift through the sea of words, often missing critical details. Students find it hard to retain information amidst the flood of discussions.\n",
        "\n",
        "2. **Lost in Translation**:\n",
        "   - **Issue**: Edenville is a multicultural community. English may be the primary language, but families speak various languages—Tamil, Telugu, and more. Communication gaps arise during parent-teacher meetings and school events.\n",
        "   - **Impact**: Parents miss out on crucial updates, and students grapple with understanding content presented in a language that isn't their native tongue.\n",
        "   \n",
        "\n",
        "In response to these challenges, the spark of innovation ignites—a vision of an AI-powered tool that transcribes, summarizes, and bridges language barriers. And thus, **SummarAI** is born, promising to transform online meetings into meaningful connections. 🌟\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "456372ba-7d13-44ed-a4a8-faa3a2550bbf",
      "metadata": {
        "id": "456372ba-7d13-44ed-a4a8-faa3a2550bbf"
      },
      "source": [
        "<div>\n",
        "<div style=\"display:flex \">\n",
        "    <div style=\"margin: auto auto auto 0\"><h2>Implementation  &#x1f6e0;</h2>  </div>\n",
        "    <div style=\" margin: auto 0 auto auto\"><b>[70 Points]</b></div>\n",
        "</div>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![](https://app.eraser.io/workspace/eT9vUMzN7YqnEFGYKlj3/preview?elements=D9PBnl00uuydyjQ-zxWuxQ&type=embed)](https://app.eraser.io/workspace/eT9vUMzN7YqnEFGYKlj3?elements=D9PBnl00uuydyjQ-zxWuxQ)"
      ],
      "metadata": {
        "id": "GVeHaw-ZnV71"
      },
      "id": "GVeHaw-ZnV71"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Package List\n",
        "\n",
        "| Package | Package | Package | Package | Package |\n",
        "|---------|---------|---------|---------|---------|\n",
        "| pandas | matplotlib | transformers | textract | langchain |\n",
        "| pypdf | openai | tiktoken | faiss-gpu | Whisper |\n",
        "| sudo apt update && sudo apt install ffmpeg | googletrans==4.0.0-rc1 | langdetect | httpx<1,>=0.23.0 | fpdf |\n",
        "| PyPDF2 | googlesearch-python | googletrans | googletrans==4.0.0-rc1 | plantuml |\n",
        "| google.generativeai | google-auth | google-auth-httplib2 | google-api-python-client | oauth2client |\n"
      ],
      "metadata": {
        "id": "9HIyrLl3oKiN"
      },
      "id": "9HIyrLl3oKiN"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install matplotlib\n",
        "!pip install transformers\n",
        "!pip install textract\n",
        "!pip install langchain\n",
        "!pip install pypdf\n",
        "!pip install openai\n",
        "!pip install tiktoken\n",
        "!pip install faiss-gpu\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!sudo apt update && sudo apt install ffmpeg\n",
        "!pip install googletrans==4.0.0-rc1\n",
        "!pip install langdetect\n",
        "!pip install \"httpx<1,>=0.23.0\"\n",
        "!pip install fpdf\n",
        "!pip install PyPDF2\n",
        "!pip install googlesearch-python\n",
        "!pip install googletrans\n",
        "!pip install --upgrade googletrans==4.0.0-rc1\n",
        "!pip install plantuml\n",
        "!pip install google.generativeai\n",
        "!pip install google-auth\n",
        "!pip install google-auth-httplib2\n",
        "!pip install google-api-python-client\n",
        "!pip install oauth2client"
      ],
      "metadata": {
        "id": "h7ruAF-4fv3N"
      },
      "id": "h7ruAF-4fv3N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature 1 - Voice to Text assistant\n",
        "\n",
        "This feature performs the following steps:\n",
        "\n",
        "1. **Transcription from Audio to Text:**\n",
        "   - Utilizes the `Whisper` tool to transcribe audio files (`audio1.mp3`) into text.\n",
        "   - Removes any timestamp information from the transcribed text.\n",
        "\n",
        "2. **Conversion to PDF:**\n",
        "   - Converts the transcribed text into a PDF document.\n",
        "   - Uses the `FPDF` library to create the PDF file.\n",
        "\n",
        "3. **Generation of Insights using GenerativeAI:**\n",
        "   - Reads the transcribed text from the PDF file.\n",
        "   - Prepares a prompt for the GenerativeAI model by combining the transcribed text with a specific instruction.\n",
        "   - Utilizes Google's GenerativeAI API, specifically the `gemini-pro` model, to generate insights based on the provided prompt.\n",
        "   - Saves the generated insights as a PDF file.\n",
        "\n",
        "Each step ensures seamless processing and conversion of audio content into readable and insightful documents.\n"
      ],
      "metadata": {
        "id": "lzKqY69JfeY1"
      },
      "id": "lzKqY69JfeY1"
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper \"/content/audio1.mp3\" --model large-v2"
      ],
      "metadata": {
        "id": "K-mGwBFzgJF9"
      },
      "id": "K-mGwBFzgJF9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca744757",
      "metadata": {
        "id": "ca744757"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from fpdf import FPDF\n",
        "import subprocess\n",
        "import google.generativeai as genai\n",
        "from PyPDF2 import PdfReader\n",
        "from fpdf import FPDF\n",
        "import textwrap\n",
        "\n",
        "def transcribe_audio(audio_file):\n",
        "    process = subprocess.Popen([\"whisper\", audio_file], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "    output, error = process.communicate()\n",
        "    transcribed_text = output.decode(\"utf-8\")\n",
        "    clean_text = re.sub(r'\\[\\d+:\\d+\\]', '', transcribed_text)\n",
        "    return clean_text\n",
        "\n",
        "def text_to_pdf(input_text, output_file):\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Arial\", size = 12)\n",
        "    pdf.multi_cell(0, 10, txt=input_text)\n",
        "    pdf.output(output_file)\n",
        "\n",
        "audio_file_path = \"/content/audio1.mp3\"\n",
        "\n",
        "transcribed_text = transcribe_audio(audio_file_path)\n",
        "\n",
        "text_file_path = \"/content/transcribed_text.txt\"\n",
        "with open(text_file_path, \"w\") as text_file:\n",
        "    text_file.write(transcribed_text)\n",
        "\n",
        "pdf_output_path = \"/content/transcribed_text.pdf\"\n",
        "text_to_pdf(transcribed_text, pdf_output_path)\n",
        "\n",
        "print(\"Transcription complete. Text saved to:\", text_file_path)\n",
        "print(\"PDF saved to:\", pdf_output_path)\n",
        "\n",
        "GOOGLE_API_KEY = \"AIzaSyBCkON8caQ_hFyx7onGVkYwkLl80WDyzBw\"\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "model = genai.GenerativeModel('gemini-pro')\n",
        "\n",
        "def read_text_from_pdf(pdf_file):\n",
        "    text = \"\"\n",
        "    with open(pdf_file, \"rb\") as f:\n",
        "        reader = PdfReader(f)\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "def write_text_to_pdf(text, output_file):\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "    pdf.multi_cell(0, 10, txt=text)\n",
        "    pdf.output(output_file)\n",
        "\n",
        "pdf_file_path = \"/content/transcribed_text.pdf\"\n",
        "transcribed_text = read_text_from_pdf(pdf_file_path)\n",
        "\n",
        "prompt = \"Convert the following content into possible PlantUML code for mindmapping:\\n\\n\" + transcribed_text\n",
        "\n",
        "response = model.generate_content(prompt)\n",
        "\n",
        "pdf_output_path = \"/content/generated_insights.pdf\"\n",
        "write_text_to_pdf(response.text, pdf_output_path)\n",
        "\n",
        "print(\"Insights have been stored in:\", pdf_output_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature 2 - Interactive QnA\n",
        "\n",
        "This feature enables interactive question-answering using a pre-trained language model. Here's the breakdown of the workflow:\n",
        "\n",
        "1. **Preparation:**\n",
        "   - Imports necessary libraries including `os`, `pandas`, `matplotlib`, `transformers`, `textract`, and several modules from `langchain` for document processing and question-answering.\n",
        "\n",
        "2. **Loading Data:**\n",
        "   - Loads the generated insights PDF document and extracts text using `textract`.\n",
        "   - Creates a knowledge base text file (`knowledge_base.txt`) for further processing.\n",
        "\n",
        "3. **Tokenization and Chunking:**\n",
        "   - Uses the GPT2 tokenizer to tokenize the text.\n",
        "   - Splits the text into manageable chunks based on token counts, ensuring efficient processing.\n",
        "\n",
        "4. **Embeddings and Vectorization:**\n",
        "   - Generates embeddings for the text chunks using OpenAI embeddings.\n",
        "   - Builds a vector store using FAISS for fast similarity search.\n",
        "\n",
        "5. **Question-Answering Setup:**\n",
        "   - Loads a question-answering chain using an OpenAI language model (`OpenAI(temperature=0)`).\n",
        "   - Creates a conversational retrieval chain based on the loaded question-answering chain and the vector store.\n",
        "\n",
        "6. **Interactive QnA Interface:**\n",
        "   - Defines an interactive interface using `ipywidgets` for users to input questions.\n",
        "   - On submission of a question, the system retrieves answers using the conversational retrieval chain.\n",
        "   - The chat history is maintained and displayed interactively.\n",
        "\n",
        "7. **Exiting the Chatbot:**\n",
        "   - Users can type 'exit' to terminate the chatbot session.\n",
        "\n",
        "This feature facilitates dynamic and interactive question-answering based on the provided knowledge base, enhancing user engagement and accessibility to information.\n"
      ],
      "metadata": {
        "id": "Xx0_xBFLgWiB"
      },
      "id": "Xx0_xBFLgWiB"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import GPT2TokenizerFast\n",
        "import textract\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "import openai\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "\n",
        "loader = PyPDFLoader(\"/content/generated_insights.pdf\")\n",
        "doc = textract.process(\"/content/generated_insights.pdf\")\n",
        "with open('knowledge_base.txt', 'w') as f:\n",
        "    f.write(doc.decode('utf-8'))\n",
        "with open('knowledge_base.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
        "def count_tokens(text: str) -> int:\n",
        "    return len(tokenizer.encode(text))\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=512,\n",
        "    chunk_overlap=24,\n",
        "    length_function=count_tokens,\n",
        ")\n",
        "chunks = text_splitter.create_documents([text])\n",
        "token_counts = [count_tokens(chunk.page_content) for chunk in chunks]\n",
        "df = pd.DataFrame({'Token Count': token_counts})\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "try:\n",
        "    db = FAISS.from_documents(chunks, embeddings)\n",
        "except TimeoutError as e:\n",
        "    print(f\"Error: Timeout - {e}\")\n",
        "except RuntimeError as e:\n",
        "    print(f\"Error: Runtime Error - {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: An unexpected error occurred - {e}\")\n",
        "\n",
        "else:\n",
        "    chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"stuff\")\n",
        "\n",
        "\n",
        "    try:\n",
        "        qa = ConversationalRetrievalChain.from_llm(OpenAI(temperature=0.1), db.as_retriever())\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating ConversationalRetrievalChain: {e}\")\n",
        "    else:\n",
        "        chat_history = []\n",
        "\n",
        "        def on_submit(_):\n",
        "            query = input_box.value\n",
        "            input_box.value = \"\"\n",
        "\n",
        "            if query.lower() == 'exit':\n",
        "                print(\"Thank you for using chatbot!\")\n",
        "                return\n",
        "\n",
        "            result = qa({\"question\": query, \"chat_history\": chat_history})\n",
        "            chat_history.append((query, result['answer']))\n",
        "\n",
        "            print(f'User: {query}')\n",
        "\n",
        "            display(widgets.HTML(f'<b><font color=\"blue\">Chatbot:</font></b> {result[\"answer\"]}'))\n",
        "\n",
        "        print(\"Welcome to the Transformers chatbot! Type 'exit' to stop.\")\n",
        "\n",
        "        input_box = widgets.Text(placeholder='Please enter your question:')\n",
        "        input_box.on_submit(on_submit)\n",
        "\n",
        "        display(input_box)\n"
      ],
      "metadata": {
        "id": "cXHEJ2e4gWAN"
      },
      "id": "cXHEJ2e4gWAN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature 3 - Summarization\n",
        "\n",
        "This feature facilitates the generation of a summary based on the provided content. Here's how it works:\n",
        "\n",
        "1. **Summary Generation Function:**\n",
        "   - Defines a function `get_summary(_)` responsible for generating a summary.\n",
        "   - Constructs a query prompting for the summary of the discussion within 100 words.\n",
        "\n",
        "2. **Summary Retrieval and Output:**\n",
        "   - Utilizes the vector store (`db`) to perform similarity search based on the provided query.\n",
        "   - Executes the summarization process using the loaded question-answering chain (`chain`) with the input documents and query.\n",
        "   - Clears the output widget (`summary_output`) and displays the generated summary within it.\n",
        "\n",
        "3. **Error Handling:**\n",
        "   - Implements exception handling to capture any errors that may occur during the summary generation process.\n",
        "   - Clears the output widget and prints the error message if an exception is encountered.\n",
        "\n",
        "4. **Interactive Interface:**\n",
        "   - Creates a button widget (`summary_button`) labeled \"Get Summary\" to trigger the summary generation process.\n",
        "   - Registers the `get_summary` function to be invoked upon clicking the button.\n",
        "\n",
        "5. **Output Display:**\n",
        "   - Renders the button widget and output widget (`summary_output`) for users to interact with.\n",
        "   - The generated summary is displayed within the output widget upon successful completion of the process.\n",
        "\n",
        "This feature streamlines the summarization of discussions or content, providing users with concise insights within a specified word limit.\n"
      ],
      "metadata": {
        "id": "4gG36ycQgo44"
      },
      "id": "4gG36ycQgo44"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_summary(_):\n",
        "\n",
        "    query = \"What is the summary of the discussion?write in 100 words\"\n",
        "\n",
        "    try:\n",
        "        docs = db.similarity_search(query)\n",
        "        result = chain.run(input_documents=docs, question=query)\n",
        "        summary_output.clear_output()\n",
        "        with summary_output:\n",
        "            print(\"Summary:\")\n",
        "            content_summary= result\n",
        "            print(result)\n",
        "\n",
        "    except Exception as e:\n",
        "        summary_output.clear_output()\n",
        "        with summary_output:\n",
        "            print(f\"Error occurred while getting summary: {e}\")\n",
        "\n",
        "summary_button = widgets.Button(description=\"Get Summary\")\n",
        "summary_button.on_click(get_summary)\n",
        "\n",
        "content_summary=\"\"\n",
        "display(summary_button)\n",
        "\n",
        "summary_output = widgets.Output()\n",
        "display(summary_output)\n"
      ],
      "metadata": {
        "id": "tt_bL0OHgoWy"
      },
      "id": "tt_bL0OHgoWy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature 4 - Generating MindMaps\n",
        "\n",
        "This feature enables the generation of mind maps from provided content using the GenerativeAI API. Here's the breakdown of the workflow:\n",
        "\n",
        "1. **API Configuration:**\n",
        "   - Configures the Google GenerativeAI API using the provided API key (`GOOGLE_API_KEY`).\n",
        "\n",
        "2. **Model Initialization:**\n",
        "   - Initializes a Generative Model (`gemini-pro`) for generating mind maps.\n",
        "\n",
        "3. **Content Retrieval:**\n",
        "   - Reads the content from a text file (`audio.txt`) to be used for mind map generation.\n",
        "\n",
        "4. **Prompt Preparation:**\n",
        "   - Constructs a prompt for the Generative Model, requesting it to convert the provided content into possible PlantUML code for mind mapping.\n",
        "   - Appends the content to the prompt for processing.\n",
        "\n",
        "5. **Content Generation:**\n",
        "   - Utilizes the Generative Model to generate content based on the constructed prompt.\n",
        "   - The response contains the PlantUML code for the mind map.\n",
        "\n",
        "6. **Output Handling:**\n",
        "   - Writes the generated PlantUML code to a file named `mindmap.png`.\n",
        "\n",
        "7. **PlantUML Execution:**\n",
        "   - Executes PlantUML to render the mind map based on the generated PlantUML code.\n",
        "   - The resulting mind map is saved as `mindmap.txt`.\n",
        "\n",
        "This feature provides a streamlined process for generating mind maps from textual content, aiding in visualizing and organizing information effectively.\n"
      ],
      "metadata": {
        "id": "_p912qXJiaML"
      },
      "id": "_p912qXJiaML"
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "GOOGLE_API_KEY = \"AIzaSyBCkON8caQ_hFyx7onGVkYwkLl80WDyzBw\"\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "model = genai.GenerativeModel('gemini-pro')\n",
        "\n",
        "with open(\"audio.txt\", \"r\") as file:\n",
        "    content = file.read()\n",
        "\n",
        "prompt = \"Convert the following content into possible PlantUML code for mindmapping the : (in the output i should not get plantuml )\"\n",
        "prompt += \"\\n\\n\" + content\n",
        "\n",
        "response = model.generate_content(prompt)\n",
        "\n",
        "with open(\"usecasediagram.png\", \"w\") as f:\n",
        "    f.write(response.text)\n",
        "\n",
        "!python -m plantuml usecasediagram.txt\n"
      ],
      "metadata": {
        "id": "hgT6si7pfdds"
      },
      "id": "hgT6si7pfdds",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature 5 - Scheduling tasks in Google Calendar\n",
        "\n",
        "This feature automates the process of scheduling tasks in Google Calendar using the GenerativeAI API. The workflow is as follows:\n",
        "\n",
        "1. **API Configuration**: Configuration of the GenerativeAI API with the provided API key.\n",
        "\n",
        "2. **Model Initialization**: Initialization of a Generative Model ('gemini-pro') for task scheduling.\n",
        "\n",
        "3. **Content Retrieval**: Retrieval of task details from a text file ('your_text_file.txt').\n",
        "\n",
        "4. **Prompt Formation**: Formation of a prompt for the Generative Model, requesting the conversion of content into an iCalendar (.ics) file with a detailed title, description, and a reminder before 10 minutes.\n",
        "\n",
        "5. **Content Generation**: Utilization of the Generative Model to generate iCalendar content based on the prompt.\n",
        "\n",
        "6. **Output Handling**: Saving the generated iCalendar content into a file named 'meeting_schedule.ics'.\n",
        "\n",
        "7. **Completion**: Confirmation message indicating the successful generation of the iCalendar file.\n",
        "\n",
        "This feature streamlines the process of scheduling tasks in Google Calendar by automating the generation of iCalendar files with detailed event information and reminders.\n"
      ],
      "metadata": {
        "id": "sf4VZ9XMi1Og"
      },
      "id": "sf4VZ9XMi1Og"
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import datetime\n",
        "\n",
        "GOOGLE_API_KEY = \"AIzaSyBCkON8caQ_hFyx7onGVkYwkLl80WDyzBw\"\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "model = genai.GenerativeModel('gemini-pro')\n",
        "\n",
        "with open(\"your_text_file.txt\", \"r\") as file:\n",
        "    content = file.read()\n",
        "\n",
        "prompt = \"Convert the following content into an iCalendar (.ics) with detailed title and description. Also a reminder before 10 mins to be added file:\\n\\n\" + content\n",
        "\n",
        "response = model.generate_content(prompt)\n",
        "\n",
        "ical_content = response.text\n",
        "\n",
        "with open(\"meeting_schedule.ics\", \"w\") as file:\n",
        "    file.write(ical_content)\n",
        "\n",
        "print(\"iCalendar file generated: meeting_schedule.ics\")"
      ],
      "metadata": {
        "id": "mVmG16m9lE1l"
      },
      "id": "mVmG16m9lE1l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature 6 - Translate\n",
        "\n",
        "This feature enables text translation into various languages using the Google Translate API. The workflow is as follows:\n",
        "\n",
        "1. **Translation Setup**: Initialization of a translator object from the Googletrans library.\n",
        "\n",
        "2. **Translation Function**: Definition of a function to translate text to the specified target language.\n",
        "\n",
        "3. **Translation and Display**: Implementation of a function to translate and display the text upon clicking the translation button.\n",
        "\n",
        "4. **User Interface**: Creation of a user interface using IPython widgets, including a dropdown menu to select the target language, a translation button, and a textarea to display the translated text.\n",
        "\n",
        "5. **Supported Languages**: Support for translation into multiple languages, including Tamil, Hindi, Spanish, French, German, Chinese (Simplified), Japanese, Korean, and Russian.\n",
        "\n",
        "This feature provides users with the ability to easily translate text into different languages, enhancing accessibility and communication across language barriers.\n"
      ],
      "metadata": {
        "id": "HDBt_OwQiWbp"
      },
      "id": "HDBt_OwQiWbp"
    },
    {
      "cell_type": "code",
      "source": [
        "from googletrans import Translator\n",
        "import ipywidgets as widgets\n",
        "\n",
        "def translate_to_language(target_language):\n",
        "    translator = Translator()\n",
        "    translated_text = translator.translate(summary_output, dest=target_language).text\n",
        "    return translated_text\n",
        "\n",
        "def translate_and_display(button):\n",
        "    target_language = language_dropdown.value\n",
        "    translated_text = translate_to_language(target_language)\n",
        "    output_text.value = translated_text\n",
        "\n",
        "output_text = widgets.Textarea(\n",
        "    placeholder='Translated text will appear here...',\n",
        "    layout=widgets.Layout(width='100%', height='200px')\n",
        ")\n",
        "\n",
        "languages = {\n",
        "    'Tamil': 'ta',\n",
        "    'Hindi': 'hi',\n",
        "    'Spanish': 'es',\n",
        "    'French': 'fr',\n",
        "    'German': 'de',\n",
        "    'Chinese (Simplified)': 'zh-cn',\n",
        "    'Japanese': 'ja',\n",
        "    'Korean': 'ko',\n",
        "    'Russian': 'ru'\n",
        "}\n",
        "\n",
        "language_dropdown = widgets.Dropdown(\n",
        "    options=languages,\n",
        "    value='ta',\n",
        "    description='Translate to:'\n",
        ")\n",
        "\n",
        "translate_button = widgets.Button(\n",
        "    description='Translate',\n",
        "    button_style='info'\n",
        ")\n",
        "translate_button.on_click(translate_and_display)\n",
        "\n",
        "widgets.VBox([\n",
        "    language_dropdown,\n",
        "    translate_button,\n",
        "    output_text\n",
        "])\n"
      ],
      "metadata": {
        "id": "VpLUPzlWfdbU"
      },
      "id": "VpLUPzlWfdbU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature 7 - Generating reference links\n",
        "\n",
        "This feature automates the process of generating reference links based on the content of a PDF document. The workflow is as follows:\n",
        "\n",
        "1. **Text Extraction**: Utilizes PyPDF2 to extract text content from the specified PDF file ('generated_insights.pdf').\n",
        "\n",
        "2. **Search Query Generation**: Divides the extracted text into keywords and generates search queries by combining them into groups of three keywords.\n",
        "\n",
        "3. **Web Search**: Performs a web search using the Google Search API for each generated query.\n",
        "\n",
        "4. **Unique Link Collection**: Collects unique links from the search results, ensuring that each link is only added once.\n",
        "\n",
        "5. **Limiting Results**: Limits the number of collected links to a specified number (5 in this case).\n",
        "\n",
        "This feature provides a quick and automated way to generate reference links related to the content of a PDF document, aiding in research and information gathering.\n"
      ],
      "metadata": {
        "id": "IZ-N1uJ2hyLC"
      },
      "id": "IZ-N1uJ2hyLC"
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "from googlesearch import search\n",
        "\n",
        "def extract_text_from_pdf(pdf_file_path):\n",
        "    with open(pdf_file_path, 'rb') as f:\n",
        "        pdf_reader = PdfReader(f)\n",
        "        text = ''\n",
        "        for page in pdf_reader.pages:\n",
        "            text += page.extract_text()\n",
        "        return text\n",
        "\n",
        "def generate_search_queries(content):\n",
        "    keywords = content.split()\n",
        "    queries = [' '.join(keywords[i:i+3]) for i in range(0, len(keywords), 3)]\n",
        "    return queries\n",
        "\n",
        "pdf_file_path = '/content/generated_insights.pdf'\n",
        "\n",
        "content = extract_text_from_pdf(pdf_file_path)\n",
        "\n",
        "search_queries = generate_search_queries(content)\n",
        "\n",
        "num_results = 5\n",
        "\n",
        "unique_links = set()\n",
        "\n",
        "for query in search_queries:\n",
        "    print(f\"Performing a web search for: {query}\")\n",
        "    for link in search(query, num=num_results):\n",
        "        if link not in unique_links:\n",
        "            unique_links.add(link)\n",
        "            print(f\"Found link: {link}\")\n",
        "        if len(unique_links) >= num_results:\n",
        "            break\n",
        "    if len(unique_links) >= num_results:\n",
        "        break\n"
      ],
      "metadata": {
        "id": "QguA_BymfdYh"
      },
      "id": "QguA_BymfdYh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "28b26aa1-28b1-4f87-85c7-40589e5abab3",
      "metadata": {
        "id": "28b26aa1-28b1-4f87-85c7-40589e5abab3"
      },
      "source": [
        "# Future Work: AI-Powered Online Meeting Enhancements\n",
        "\n",
        "## 1. Enhanced Transcription Accuracy\n",
        "\n",
        "- **Issue**: Our current transcription model performs well, but there’s room for improvement.\n",
        "- **Context**: Accents, technical terms, and background noise can hinder accurate transcription.\n",
        "- **Solution**: Leverage advanced ASR techniques such as **Gemini Pro**, a state-of-the-art automatic speech recognition system. Fine-tune it using a combination of **OpenAI’s GPT-4** and **LangChain**—a proprietary language modeling framework.\n",
        "\n",
        "## 2. Automated Action Item Extraction\n",
        "\n",
        "- **Issue**: Users spend time manually identifying action items from meeting summaries.\n",
        "- **Context**: Action items drive follow-up tasks and decisions.\n",
        "- **Solution**: Implement a rule-based system using **LangChain** to recognize action-oriented phrases (e.g., “assign,” “follow up,” “deadline”). Additionally, explore **LLM (Language Learning Models)** to improve context-aware extraction.\n",
        "\n",
        "## 3. Customizable Mind Map Templates\n",
        "\n",
        "- **Issue**: Mind maps are powerful visual tools, but a one-size-fits-all approach may not suit everyone.\n",
        "- **Context**: Users have different preferences for mind map structures.\n",
        "- **Solution**: Integrate **MindMapPro**, an open-source tool that allows users to create custom mind map templates. Leverage **GPT-4** for personalized recommendations on node arrangement and color schemes.\n",
        "\n",
        "## 4. Contextual Question-Answering\n",
        "\n",
        "- **Issue**: Current Q&A sessions provide standalone answers without considering context.\n",
        "- **Context**: Conversations evolve, and context matters for accurate responses.\n",
        "- **Solution**: Enhance our AI using **OpenAI’s ChatGPT** with fine-tuning on domain-specific data. Maintain context by incorporating **LangChain’s Memory Networks** for better contextual understanding.\n",
        "\n",
        "## 5. Real-Time Sentiment Analysis\n",
        "\n",
        "- **Issue**: Meetings carry emotional tones—positive, negative, or neutral.\n",
        "- **Context**: Understanding sentiment helps gauge participants’ reactions.\n",
        "- **Solution**: Implement real-time sentiment analysis using **Gemini Pro**. Combine it with **GPT-4** for context-aware sentiment interpretation.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}